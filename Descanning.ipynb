{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 384
    },
    "id": "RXPlPKwDBTkC",
    "outputId": "59769338-fd58-4efd-8d21-c2ab58222cf4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/owiequhf/anaconda3/envs/mlvc/lib/python3.10/site-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 16, 128, 128]             448\n",
      "       LayerNorm2d-2         [-1, 16, 128, 128]              32\n",
      " AdaptiveAvgPool2d-3             [-1, 16, 1, 1]               0\n",
      "            Conv2d-4             [-1, 16, 1, 1]             272\n",
      "            Conv2d-5         [-1, 16, 128, 128]             272\n",
      "            Conv2d-6         [-1, 16, 128, 128]           1,616\n",
      "            Conv2d-7         [-1, 16, 128, 128]             160\n",
      "        SimpleGate-8          [-1, 8, 128, 128]               0\n",
      "            Conv2d-9         [-1, 32, 128, 128]             288\n",
      "           Conv2d-10         [-1, 32, 128, 128]             544\n",
      "           Conv2d-11         [-1, 16, 128, 128]             272\n",
      "           Conv2d-12         [-1, 16, 128, 128]             160\n",
      "           Conv2d-13         [-1, 16, 128, 128]             272\n",
      "         Identity-14         [-1, 16, 128, 128]               0\n",
      "      LayerNorm2d-15         [-1, 16, 128, 128]              32\n",
      "           Conv2d-16         [-1, 32, 128, 128]             544\n",
      "       SimpleGate-17         [-1, 16, 128, 128]               0\n",
      "           Conv2d-18         [-1, 16, 128, 128]             272\n",
      "         Identity-19         [-1, 16, 128, 128]               0\n",
      "        KBBlock_s-20         [-1, 16, 128, 128]               0\n",
      "      LayerNorm2d-21         [-1, 16, 128, 128]              32\n",
      "AdaptiveAvgPool2d-22             [-1, 16, 1, 1]               0\n",
      "           Conv2d-23             [-1, 16, 1, 1]             272\n",
      "           Conv2d-24         [-1, 16, 128, 128]             272\n",
      "           Conv2d-25         [-1, 16, 128, 128]           1,616\n",
      "           Conv2d-26         [-1, 16, 128, 128]             160\n",
      "       SimpleGate-27          [-1, 8, 128, 128]               0\n",
      "           Conv2d-28         [-1, 32, 128, 128]             288\n",
      "           Conv2d-29         [-1, 32, 128, 128]             544\n",
      "           Conv2d-30         [-1, 16, 128, 128]             272\n",
      "           Conv2d-31         [-1, 16, 128, 128]             160\n",
      "           Conv2d-32         [-1, 16, 128, 128]             272\n",
      "         Identity-33         [-1, 16, 128, 128]               0\n",
      "      LayerNorm2d-34         [-1, 16, 128, 128]              32\n",
      "           Conv2d-35         [-1, 32, 128, 128]             544\n",
      "       SimpleGate-36         [-1, 16, 128, 128]               0\n",
      "           Conv2d-37         [-1, 16, 128, 128]             272\n",
      "         Identity-38         [-1, 16, 128, 128]               0\n",
      "        KBBlock_s-39         [-1, 16, 128, 128]               0\n",
      "           Conv2d-40           [-1, 32, 64, 64]           2,080\n",
      "      LayerNorm2d-41           [-1, 32, 64, 64]              64\n",
      "AdaptiveAvgPool2d-42             [-1, 32, 1, 1]               0\n",
      "           Conv2d-43             [-1, 32, 1, 1]           1,056\n",
      "           Conv2d-44           [-1, 32, 64, 64]           1,056\n",
      "           Conv2d-45           [-1, 32, 64, 64]           3,232\n",
      "           Conv2d-46           [-1, 32, 64, 64]             320\n",
      "       SimpleGate-47           [-1, 16, 64, 64]               0\n",
      "           Conv2d-48           [-1, 32, 64, 64]             544\n",
      "           Conv2d-49           [-1, 32, 64, 64]           1,056\n",
      "           Conv2d-50           [-1, 32, 64, 64]           1,056\n",
      "           Conv2d-51           [-1, 32, 64, 64]             320\n",
      "           Conv2d-52           [-1, 32, 64, 64]           1,056\n",
      "         Identity-53           [-1, 32, 64, 64]               0\n",
      "      LayerNorm2d-54           [-1, 32, 64, 64]              64\n",
      "           Conv2d-55           [-1, 64, 64, 64]           2,112\n",
      "       SimpleGate-56           [-1, 32, 64, 64]               0\n",
      "           Conv2d-57           [-1, 32, 64, 64]           1,056\n",
      "         Identity-58           [-1, 32, 64, 64]               0\n",
      "        KBBlock_s-59           [-1, 32, 64, 64]               0\n",
      "      LayerNorm2d-60           [-1, 32, 64, 64]              64\n",
      "AdaptiveAvgPool2d-61             [-1, 32, 1, 1]               0\n",
      "           Conv2d-62             [-1, 32, 1, 1]           1,056\n",
      "           Conv2d-63           [-1, 32, 64, 64]           1,056\n",
      "           Conv2d-64           [-1, 32, 64, 64]           3,232\n",
      "           Conv2d-65           [-1, 32, 64, 64]             320\n",
      "       SimpleGate-66           [-1, 16, 64, 64]               0\n",
      "           Conv2d-67           [-1, 32, 64, 64]             544\n",
      "           Conv2d-68           [-1, 32, 64, 64]           1,056\n",
      "           Conv2d-69           [-1, 32, 64, 64]           1,056\n",
      "           Conv2d-70           [-1, 32, 64, 64]             320\n",
      "           Conv2d-71           [-1, 32, 64, 64]           1,056\n",
      "         Identity-72           [-1, 32, 64, 64]               0\n",
      "      LayerNorm2d-73           [-1, 32, 64, 64]              64\n",
      "           Conv2d-74           [-1, 64, 64, 64]           2,112\n",
      "       SimpleGate-75           [-1, 32, 64, 64]               0\n",
      "           Conv2d-76           [-1, 32, 64, 64]           1,056\n",
      "         Identity-77           [-1, 32, 64, 64]               0\n",
      "        KBBlock_s-78           [-1, 32, 64, 64]               0\n",
      "           Conv2d-79           [-1, 64, 32, 32]           8,256\n",
      "      LayerNorm2d-80           [-1, 64, 32, 32]             128\n",
      "AdaptiveAvgPool2d-81             [-1, 64, 1, 1]               0\n",
      "           Conv2d-82             [-1, 64, 1, 1]           4,160\n",
      "           Conv2d-83           [-1, 64, 32, 32]           4,160\n",
      "           Conv2d-84           [-1, 64, 32, 32]           6,464\n",
      "           Conv2d-85           [-1, 32, 32, 32]             608\n",
      "       SimpleGate-86           [-1, 16, 32, 32]               0\n",
      "           Conv2d-87           [-1, 32, 32, 32]             544\n",
      "           Conv2d-88           [-1, 32, 32, 32]           2,080\n",
      "           Conv2d-89           [-1, 64, 32, 32]           4,160\n",
      "           Conv2d-90           [-1, 64, 32, 32]             640\n",
      "           Conv2d-91           [-1, 64, 32, 32]           4,160\n",
      "         Identity-92           [-1, 64, 32, 32]               0\n",
      "      LayerNorm2d-93           [-1, 64, 32, 32]             128\n",
      "           Conv2d-94          [-1, 128, 32, 32]           8,320\n",
      "       SimpleGate-95           [-1, 64, 32, 32]               0\n",
      "           Conv2d-96           [-1, 64, 32, 32]           4,160\n",
      "         Identity-97           [-1, 64, 32, 32]               0\n",
      "        KBBlock_s-98           [-1, 64, 32, 32]               0\n",
      "      LayerNorm2d-99           [-1, 64, 32, 32]             128\n",
      "AdaptiveAvgPool2d-100             [-1, 64, 1, 1]               0\n",
      "          Conv2d-101             [-1, 64, 1, 1]           4,160\n",
      "          Conv2d-102           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-103           [-1, 64, 32, 32]           6,464\n",
      "          Conv2d-104           [-1, 32, 32, 32]             608\n",
      "      SimpleGate-105           [-1, 16, 32, 32]               0\n",
      "          Conv2d-106           [-1, 32, 32, 32]             544\n",
      "          Conv2d-107           [-1, 32, 32, 32]           2,080\n",
      "          Conv2d-108           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-109           [-1, 64, 32, 32]             640\n",
      "          Conv2d-110           [-1, 64, 32, 32]           4,160\n",
      "        Identity-111           [-1, 64, 32, 32]               0\n",
      "     LayerNorm2d-112           [-1, 64, 32, 32]             128\n",
      "          Conv2d-113          [-1, 128, 32, 32]           8,320\n",
      "      SimpleGate-114           [-1, 64, 32, 32]               0\n",
      "          Conv2d-115           [-1, 64, 32, 32]           4,160\n",
      "        Identity-116           [-1, 64, 32, 32]               0\n",
      "       KBBlock_s-117           [-1, 64, 32, 32]               0\n",
      "          Conv2d-118          [-1, 128, 16, 16]          32,896\n",
      "     LayerNorm2d-119          [-1, 128, 16, 16]             256\n",
      "AdaptiveAvgPool2d-120            [-1, 128, 1, 1]               0\n",
      "          Conv2d-121            [-1, 128, 1, 1]          16,512\n",
      "          Conv2d-122          [-1, 128, 16, 16]          16,512\n",
      "          Conv2d-123          [-1, 128, 16, 16]          12,928\n",
      "          Conv2d-124           [-1, 32, 16, 16]           1,184\n",
      "      SimpleGate-125           [-1, 16, 16, 16]               0\n",
      "          Conv2d-126           [-1, 32, 16, 16]             544\n",
      "          Conv2d-127           [-1, 32, 16, 16]           4,128\n",
      "          Conv2d-128          [-1, 128, 16, 16]          16,512\n",
      "          Conv2d-129          [-1, 128, 16, 16]           1,280\n",
      "          Conv2d-130          [-1, 128, 16, 16]          16,512\n",
      "        Identity-131          [-1, 128, 16, 16]               0\n",
      "     LayerNorm2d-132          [-1, 128, 16, 16]             256\n",
      "          Conv2d-133          [-1, 256, 16, 16]          33,024\n",
      "      SimpleGate-134          [-1, 128, 16, 16]               0\n",
      "          Conv2d-135          [-1, 128, 16, 16]          16,512\n",
      "        Identity-136          [-1, 128, 16, 16]               0\n",
      "       KBBlock_s-137          [-1, 128, 16, 16]               0\n",
      "     LayerNorm2d-138          [-1, 128, 16, 16]             256\n",
      "AdaptiveAvgPool2d-139            [-1, 128, 1, 1]               0\n",
      "          Conv2d-140            [-1, 128, 1, 1]          16,512\n",
      "          Conv2d-141          [-1, 128, 16, 16]          16,512\n",
      "          Conv2d-142          [-1, 128, 16, 16]          12,928\n",
      "          Conv2d-143           [-1, 32, 16, 16]           1,184\n",
      "      SimpleGate-144           [-1, 16, 16, 16]               0\n",
      "          Conv2d-145           [-1, 32, 16, 16]             544\n",
      "          Conv2d-146           [-1, 32, 16, 16]           4,128\n",
      "          Conv2d-147          [-1, 128, 16, 16]          16,512\n",
      "          Conv2d-148          [-1, 128, 16, 16]           1,280\n",
      "          Conv2d-149          [-1, 128, 16, 16]          16,512\n",
      "        Identity-150          [-1, 128, 16, 16]               0\n",
      "     LayerNorm2d-151          [-1, 128, 16, 16]             256\n",
      "          Conv2d-152          [-1, 256, 16, 16]          33,024\n",
      "      SimpleGate-153          [-1, 128, 16, 16]               0\n",
      "          Conv2d-154          [-1, 128, 16, 16]          16,512\n",
      "        Identity-155          [-1, 128, 16, 16]               0\n",
      "       KBBlock_s-156          [-1, 128, 16, 16]               0\n",
      "     LayerNorm2d-157          [-1, 128, 16, 16]             256\n",
      "AdaptiveAvgPool2d-158            [-1, 128, 1, 1]               0\n",
      "          Conv2d-159            [-1, 128, 1, 1]          16,512\n",
      "          Conv2d-160          [-1, 128, 16, 16]          16,512\n",
      "          Conv2d-161          [-1, 128, 16, 16]          12,928\n",
      "          Conv2d-162           [-1, 32, 16, 16]           1,184\n",
      "      SimpleGate-163           [-1, 16, 16, 16]               0\n",
      "          Conv2d-164           [-1, 32, 16, 16]             544\n",
      "          Conv2d-165           [-1, 32, 16, 16]           4,128\n",
      "          Conv2d-166          [-1, 128, 16, 16]          16,512\n",
      "          Conv2d-167          [-1, 128, 16, 16]           1,280\n",
      "          Conv2d-168          [-1, 128, 16, 16]          16,512\n",
      "        Identity-169          [-1, 128, 16, 16]               0\n",
      "     LayerNorm2d-170          [-1, 128, 16, 16]             256\n",
      "          Conv2d-171          [-1, 256, 16, 16]          33,024\n",
      "      SimpleGate-172          [-1, 128, 16, 16]               0\n",
      "          Conv2d-173          [-1, 128, 16, 16]          16,512\n",
      "        Identity-174          [-1, 128, 16, 16]               0\n",
      "       KBBlock_s-175          [-1, 128, 16, 16]               0\n",
      "     LayerNorm2d-176          [-1, 128, 16, 16]             256\n",
      "AdaptiveAvgPool2d-177            [-1, 128, 1, 1]               0\n",
      "          Conv2d-178            [-1, 128, 1, 1]          16,512\n",
      "          Conv2d-179          [-1, 128, 16, 16]          16,512\n",
      "          Conv2d-180          [-1, 128, 16, 16]          12,928\n",
      "          Conv2d-181           [-1, 32, 16, 16]           1,184\n",
      "      SimpleGate-182           [-1, 16, 16, 16]               0\n",
      "          Conv2d-183           [-1, 32, 16, 16]             544\n",
      "          Conv2d-184           [-1, 32, 16, 16]           4,128\n",
      "          Conv2d-185          [-1, 128, 16, 16]          16,512\n",
      "          Conv2d-186          [-1, 128, 16, 16]           1,280\n",
      "          Conv2d-187          [-1, 128, 16, 16]          16,512\n",
      "        Identity-188          [-1, 128, 16, 16]               0\n",
      "     LayerNorm2d-189          [-1, 128, 16, 16]             256\n",
      "          Conv2d-190          [-1, 256, 16, 16]          33,024\n",
      "      SimpleGate-191          [-1, 128, 16, 16]               0\n",
      "          Conv2d-192          [-1, 128, 16, 16]          16,512\n",
      "        Identity-193          [-1, 128, 16, 16]               0\n",
      "       KBBlock_s-194          [-1, 128, 16, 16]               0\n",
      "          Conv2d-195          [-1, 256, 16, 16]          32,768\n",
      "    PixelShuffle-196           [-1, 64, 32, 32]               0\n",
      "     LayerNorm2d-197           [-1, 64, 32, 32]             128\n",
      "AdaptiveAvgPool2d-198             [-1, 64, 1, 1]               0\n",
      "          Conv2d-199             [-1, 64, 1, 1]           4,160\n",
      "          Conv2d-200           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-201           [-1, 64, 32, 32]           6,464\n",
      "          Conv2d-202           [-1, 32, 32, 32]             608\n",
      "      SimpleGate-203           [-1, 16, 32, 32]               0\n",
      "          Conv2d-204           [-1, 32, 32, 32]             544\n",
      "          Conv2d-205           [-1, 32, 32, 32]           2,080\n",
      "          Conv2d-206           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-207           [-1, 64, 32, 32]             640\n",
      "          Conv2d-208           [-1, 64, 32, 32]           4,160\n",
      "        Identity-209           [-1, 64, 32, 32]               0\n",
      "     LayerNorm2d-210           [-1, 64, 32, 32]             128\n",
      "          Conv2d-211          [-1, 128, 32, 32]           8,320\n",
      "      SimpleGate-212           [-1, 64, 32, 32]               0\n",
      "          Conv2d-213           [-1, 64, 32, 32]           4,160\n",
      "        Identity-214           [-1, 64, 32, 32]               0\n",
      "       KBBlock_s-215           [-1, 64, 32, 32]               0\n",
      "     LayerNorm2d-216           [-1, 64, 32, 32]             128\n",
      "AdaptiveAvgPool2d-217             [-1, 64, 1, 1]               0\n",
      "          Conv2d-218             [-1, 64, 1, 1]           4,160\n",
      "          Conv2d-219           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-220           [-1, 64, 32, 32]           6,464\n",
      "          Conv2d-221           [-1, 32, 32, 32]             608\n",
      "      SimpleGate-222           [-1, 16, 32, 32]               0\n",
      "          Conv2d-223           [-1, 32, 32, 32]             544\n",
      "          Conv2d-224           [-1, 32, 32, 32]           2,080\n",
      "          Conv2d-225           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-226           [-1, 64, 32, 32]             640\n",
      "          Conv2d-227           [-1, 64, 32, 32]           4,160\n",
      "        Identity-228           [-1, 64, 32, 32]               0\n",
      "     LayerNorm2d-229           [-1, 64, 32, 32]             128\n",
      "          Conv2d-230          [-1, 128, 32, 32]           8,320\n",
      "      SimpleGate-231           [-1, 64, 32, 32]               0\n",
      "          Conv2d-232           [-1, 64, 32, 32]           4,160\n",
      "        Identity-233           [-1, 64, 32, 32]               0\n",
      "       KBBlock_s-234           [-1, 64, 32, 32]               0\n",
      "     LayerNorm2d-235           [-1, 64, 32, 32]             128\n",
      "AdaptiveAvgPool2d-236             [-1, 64, 1, 1]               0\n",
      "          Conv2d-237             [-1, 64, 1, 1]           4,160\n",
      "          Conv2d-238           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-239           [-1, 64, 32, 32]           6,464\n",
      "          Conv2d-240           [-1, 32, 32, 32]             608\n",
      "      SimpleGate-241           [-1, 16, 32, 32]               0\n",
      "          Conv2d-242           [-1, 32, 32, 32]             544\n",
      "          Conv2d-243           [-1, 32, 32, 32]           2,080\n",
      "          Conv2d-244           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-245           [-1, 64, 32, 32]             640\n",
      "          Conv2d-246           [-1, 64, 32, 32]           4,160\n",
      "        Identity-247           [-1, 64, 32, 32]               0\n",
      "     LayerNorm2d-248           [-1, 64, 32, 32]             128\n",
      "          Conv2d-249          [-1, 128, 32, 32]           8,320\n",
      "      SimpleGate-250           [-1, 64, 32, 32]               0\n",
      "          Conv2d-251           [-1, 64, 32, 32]           4,160\n",
      "        Identity-252           [-1, 64, 32, 32]               0\n",
      "       KBBlock_s-253           [-1, 64, 32, 32]               0\n",
      "     LayerNorm2d-254           [-1, 64, 32, 32]             128\n",
      "AdaptiveAvgPool2d-255             [-1, 64, 1, 1]               0\n",
      "          Conv2d-256             [-1, 64, 1, 1]           4,160\n",
      "          Conv2d-257           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-258           [-1, 64, 32, 32]           6,464\n",
      "          Conv2d-259           [-1, 32, 32, 32]             608\n",
      "      SimpleGate-260           [-1, 16, 32, 32]               0\n",
      "          Conv2d-261           [-1, 32, 32, 32]             544\n",
      "          Conv2d-262           [-1, 32, 32, 32]           2,080\n",
      "          Conv2d-263           [-1, 64, 32, 32]           4,160\n",
      "          Conv2d-264           [-1, 64, 32, 32]             640\n",
      "          Conv2d-265           [-1, 64, 32, 32]           4,160\n",
      "        Identity-266           [-1, 64, 32, 32]               0\n",
      "     LayerNorm2d-267           [-1, 64, 32, 32]             128\n",
      "          Conv2d-268          [-1, 128, 32, 32]           8,320\n",
      "      SimpleGate-269           [-1, 64, 32, 32]               0\n",
      "          Conv2d-270           [-1, 64, 32, 32]           4,160\n",
      "        Identity-271           [-1, 64, 32, 32]               0\n",
      "       KBBlock_s-272           [-1, 64, 32, 32]               0\n",
      "          Conv2d-273          [-1, 128, 32, 32]           8,192\n",
      "    PixelShuffle-274           [-1, 32, 64, 64]               0\n",
      "     LayerNorm2d-275           [-1, 32, 64, 64]              64\n",
      "AdaptiveAvgPool2d-276             [-1, 32, 1, 1]               0\n",
      "          Conv2d-277             [-1, 32, 1, 1]           1,056\n",
      "          Conv2d-278           [-1, 32, 64, 64]           1,056\n",
      "          Conv2d-279           [-1, 32, 64, 64]           3,232\n",
      "          Conv2d-280           [-1, 32, 64, 64]             320\n",
      "      SimpleGate-281           [-1, 16, 64, 64]               0\n",
      "          Conv2d-282           [-1, 32, 64, 64]             544\n",
      "          Conv2d-283           [-1, 32, 64, 64]           1,056\n",
      "          Conv2d-284           [-1, 32, 64, 64]           1,056\n",
      "          Conv2d-285           [-1, 32, 64, 64]             320\n",
      "          Conv2d-286           [-1, 32, 64, 64]           1,056\n",
      "        Identity-287           [-1, 32, 64, 64]               0\n",
      "     LayerNorm2d-288           [-1, 32, 64, 64]              64\n",
      "          Conv2d-289           [-1, 64, 64, 64]           2,112\n",
      "      SimpleGate-290           [-1, 32, 64, 64]               0\n",
      "          Conv2d-291           [-1, 32, 64, 64]           1,056\n",
      "        Identity-292           [-1, 32, 64, 64]               0\n",
      "       KBBlock_s-293           [-1, 32, 64, 64]               0\n",
      "     LayerNorm2d-294           [-1, 32, 64, 64]              64\n",
      "AdaptiveAvgPool2d-295             [-1, 32, 1, 1]               0\n",
      "          Conv2d-296             [-1, 32, 1, 1]           1,056\n",
      "          Conv2d-297           [-1, 32, 64, 64]           1,056\n",
      "          Conv2d-298           [-1, 32, 64, 64]           3,232\n",
      "          Conv2d-299           [-1, 32, 64, 64]             320\n",
      "      SimpleGate-300           [-1, 16, 64, 64]               0\n",
      "          Conv2d-301           [-1, 32, 64, 64]             544\n",
      "          Conv2d-302           [-1, 32, 64, 64]           1,056\n",
      "          Conv2d-303           [-1, 32, 64, 64]           1,056\n",
      "          Conv2d-304           [-1, 32, 64, 64]             320\n",
      "          Conv2d-305           [-1, 32, 64, 64]           1,056\n",
      "        Identity-306           [-1, 32, 64, 64]               0\n",
      "     LayerNorm2d-307           [-1, 32, 64, 64]              64\n",
      "          Conv2d-308           [-1, 64, 64, 64]           2,112\n",
      "      SimpleGate-309           [-1, 32, 64, 64]               0\n",
      "          Conv2d-310           [-1, 32, 64, 64]           1,056\n",
      "        Identity-311           [-1, 32, 64, 64]               0\n",
      "       KBBlock_s-312           [-1, 32, 64, 64]               0\n",
      "     LayerNorm2d-313           [-1, 32, 64, 64]              64\n",
      "AdaptiveAvgPool2d-314             [-1, 32, 1, 1]               0\n",
      "          Conv2d-315             [-1, 32, 1, 1]           1,056\n",
      "          Conv2d-316           [-1, 32, 64, 64]           1,056\n",
      "          Conv2d-317           [-1, 32, 64, 64]           3,232\n",
      "          Conv2d-318           [-1, 32, 64, 64]             320\n",
      "      SimpleGate-319           [-1, 16, 64, 64]               0\n",
      "          Conv2d-320           [-1, 32, 64, 64]             544\n",
      "          Conv2d-321           [-1, 32, 64, 64]           1,056\n",
      "          Conv2d-322           [-1, 32, 64, 64]           1,056\n",
      "          Conv2d-323           [-1, 32, 64, 64]             320\n",
      "          Conv2d-324           [-1, 32, 64, 64]           1,056\n",
      "        Identity-325           [-1, 32, 64, 64]               0\n",
      "     LayerNorm2d-326           [-1, 32, 64, 64]              64\n",
      "          Conv2d-327           [-1, 64, 64, 64]           2,112\n",
      "      SimpleGate-328           [-1, 32, 64, 64]               0\n",
      "          Conv2d-329           [-1, 32, 64, 64]           1,056\n",
      "        Identity-330           [-1, 32, 64, 64]               0\n",
      "       KBBlock_s-331           [-1, 32, 64, 64]               0\n",
      "          Conv2d-332           [-1, 64, 64, 64]           2,048\n",
      "    PixelShuffle-333         [-1, 16, 128, 128]               0\n",
      "     LayerNorm2d-334         [-1, 16, 128, 128]              32\n",
      "AdaptiveAvgPool2d-335             [-1, 16, 1, 1]               0\n",
      "          Conv2d-336             [-1, 16, 1, 1]             272\n",
      "          Conv2d-337         [-1, 16, 128, 128]             272\n",
      "          Conv2d-338         [-1, 16, 128, 128]           1,616\n",
      "          Conv2d-339         [-1, 16, 128, 128]             160\n",
      "      SimpleGate-340          [-1, 8, 128, 128]               0\n",
      "          Conv2d-341         [-1, 32, 128, 128]             288\n",
      "          Conv2d-342         [-1, 32, 128, 128]             544\n",
      "          Conv2d-343         [-1, 16, 128, 128]             272\n",
      "          Conv2d-344         [-1, 16, 128, 128]             160\n",
      "          Conv2d-345         [-1, 16, 128, 128]             272\n",
      "        Identity-346         [-1, 16, 128, 128]               0\n",
      "     LayerNorm2d-347         [-1, 16, 128, 128]              32\n",
      "          Conv2d-348         [-1, 32, 128, 128]             544\n",
      "      SimpleGate-349         [-1, 16, 128, 128]               0\n",
      "          Conv2d-350         [-1, 16, 128, 128]             272\n",
      "        Identity-351         [-1, 16, 128, 128]               0\n",
      "       KBBlock_s-352         [-1, 16, 128, 128]               0\n",
      "     LayerNorm2d-353         [-1, 16, 128, 128]              32\n",
      "AdaptiveAvgPool2d-354             [-1, 16, 1, 1]               0\n",
      "          Conv2d-355             [-1, 16, 1, 1]             272\n",
      "          Conv2d-356         [-1, 16, 128, 128]             272\n",
      "          Conv2d-357         [-1, 16, 128, 128]           1,616\n",
      "          Conv2d-358         [-1, 16, 128, 128]             160\n",
      "      SimpleGate-359          [-1, 8, 128, 128]               0\n",
      "          Conv2d-360         [-1, 32, 128, 128]             288\n",
      "          Conv2d-361         [-1, 32, 128, 128]             544\n",
      "          Conv2d-362         [-1, 16, 128, 128]             272\n",
      "          Conv2d-363         [-1, 16, 128, 128]             160\n",
      "          Conv2d-364         [-1, 16, 128, 128]             272\n",
      "        Identity-365         [-1, 16, 128, 128]               0\n",
      "     LayerNorm2d-366         [-1, 16, 128, 128]              32\n",
      "          Conv2d-367         [-1, 32, 128, 128]             544\n",
      "      SimpleGate-368         [-1, 16, 128, 128]               0\n",
      "          Conv2d-369         [-1, 16, 128, 128]             272\n",
      "        Identity-370         [-1, 16, 128, 128]               0\n",
      "       KBBlock_s-371         [-1, 16, 128, 128]               0\n",
      "          Conv2d-372          [-1, 3, 128, 128]             435\n",
      "================================================================\n",
      "Total params: 953,939\n",
      "Trainable params: 953,939\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 316.77\n",
      "Params size (MB): 3.64\n",
      "Estimated Total Size (MB): 320.59\n",
      "----------------------------------------------------------------\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 0.0254\n",
      "\n",
      "Epoch 1/30, Valid set : Average loss: 0.0095\n",
      "\n",
      "Saved model checkpoint at epoch 1\n",
      "Epoch 2/30, Loss: 0.0080\n",
      "\n",
      "Epoch 2/30, Valid set : Average loss: 0.0079\n",
      "\n",
      "Saved model checkpoint at epoch 2\n",
      "Epoch 3/30, Loss: 0.0072\n",
      "\n",
      "Epoch 3/30, Valid set : Average loss: 0.0075\n",
      "\n",
      "Saved model checkpoint at epoch 3\n",
      "Epoch 4/30, Loss: 0.0068\n",
      "\n",
      "Epoch 4/30, Valid set : Average loss: 0.0063\n",
      "\n",
      "Saved model checkpoint at epoch 4\n",
      "Epoch 5/30, Loss: 0.0063\n",
      "\n",
      "Epoch 5/30, Valid set : Average loss: 0.0066\n",
      "\n",
      "Epoch 6/30, Loss: 0.0062\n",
      "\n",
      "Epoch 6/30, Valid set : Average loss: 0.0059\n",
      "\n",
      "Saved model checkpoint at epoch 6\n",
      "Epoch 7/30, Loss: 0.0061\n",
      "\n",
      "Epoch 7/30, Valid set : Average loss: 0.0062\n",
      "\n",
      "Epoch 8/30, Loss: 0.0057\n",
      "\n",
      "Epoch 8/30, Valid set : Average loss: 0.0060\n",
      "\n",
      "Epoch 9/30, Loss: 0.0057\n",
      "\n",
      "Epoch 9/30, Valid set : Average loss: 0.0057\n",
      "\n",
      "Saved model checkpoint at epoch 9\n",
      "Epoch 10/30, Loss: 0.0058\n",
      "\n",
      "Epoch 10/30, Valid set : Average loss: 0.0060\n",
      "\n",
      "Epoch 11/30, Loss: 0.0058\n",
      "\n",
      "Epoch 11/30, Valid set : Average loss: 0.0056\n",
      "\n",
      "Saved model checkpoint at epoch 11\n",
      "Epoch 12/30, Loss: 0.0056\n",
      "\n",
      "Epoch 12/30, Valid set : Average loss: 0.0055\n",
      "\n",
      "Saved model checkpoint at epoch 12\n",
      "Epoch 13/30, Loss: 0.0054\n",
      "\n",
      "Epoch 13/30, Valid set : Average loss: 0.0057\n",
      "\n",
      "Epoch 14/30, Loss: 0.0055\n",
      "\n",
      "Epoch 14/30, Valid set : Average loss: 0.0058\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor, Normalize, Compose\n",
    "from os.path import join\n",
    "from os import listdir\n",
    "from torchsummary import summary\n",
    "import time\n",
    "import zipfile\n",
    "from os.path import splitext\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "import csv\n",
    "import basicsr\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "import math\n",
    "from PIL import Image\n",
    "from torch.utils.data import Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torch.nn.init as init\n",
    "import mmap\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#스케쥴러를 expotential로 바꿈. \n",
    "#모델 구조는 동일\n",
    "#epoch는 70 for 학습률이 0.0001보다 작어졌을 때 더 좋은지 알아보려고\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 랜덤 시드 고정\n",
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "\n",
    "\n",
    "# 시작 시간 기록\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "num_epochs = 30\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "channel = 3\n",
    "\n",
    "# -----------------------------define--------------------------------\n",
    "\n",
    "# 이미지 로드 함수 정의\n",
    "def load_img(filepath):\n",
    "    img = cv2.imread(filepath)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n",
    "\n",
    "class KBAFunction(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, att, selfk, selfg, selfb, selfw):\n",
    "        B, nset, H, W = att.shape\n",
    "        KK = selfk ** 2\n",
    "        selfc = x.shape[1]\n",
    "\n",
    "        att = att.reshape(B, nset, H * W).transpose(-2, -1)\n",
    "\n",
    "        ctx.selfk, ctx.selfg, ctx.selfc, ctx.KK, ctx.nset = selfk, selfg, selfc, KK, nset\n",
    "        ctx.x, ctx.att, ctx.selfb, ctx.selfw = x, att, selfb, selfw\n",
    "\n",
    "        bias = att @ selfb\n",
    "        attk = att @ selfw\n",
    "\n",
    "        uf = torch.nn.functional.unfold(x, kernel_size=selfk, padding=selfk // 2)\n",
    "\n",
    "        # for unfold att / less memory cost\n",
    "        uf = uf.reshape(B, selfg, selfc // selfg * KK, H * W).permute(0, 3, 1, 2)\n",
    "        attk = attk.reshape(B, H * W, selfg, selfc // selfg, selfc // selfg * KK)\n",
    "\n",
    "        x = attk @ uf.unsqueeze(-1)  #\n",
    "        del attk, uf\n",
    "        x = x.squeeze(-1).reshape(B, H * W, selfc) + bias\n",
    "        x = x.transpose(-1, -2).reshape(B, selfc, H, W)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        x, att, selfb, selfw = ctx.x, ctx.att, ctx.selfb, ctx.selfw\n",
    "        selfk, selfg, selfc, KK, nset = ctx.selfk, ctx.selfg, ctx.selfc, ctx.KK, ctx.nset\n",
    "\n",
    "        B, selfc, H, W = grad_output.size()\n",
    "\n",
    "        dbias = grad_output.reshape(B, selfc, H * W).transpose(-1, -2)\n",
    "\n",
    "        dselfb = att.transpose(-2, -1) @ dbias\n",
    "        datt = dbias @ selfb.transpose(-2, -1)\n",
    "\n",
    "        attk = att @ selfw\n",
    "        uf = F.unfold(x, kernel_size=selfk, padding=selfk // 2)\n",
    "        # for unfold att / less memory cost\n",
    "        uf = uf.reshape(B, selfg, selfc // selfg * KK, H * W).permute(0, 3, 1, 2)\n",
    "        attk = attk.reshape(B, H * W, selfg, selfc // selfg, selfc // selfg * KK)\n",
    "\n",
    "        dx = dbias.view(B, H * W, selfg, selfc // selfg, 1)\n",
    "\n",
    "        dattk = dx @ uf.view(B, H * W, selfg, 1, selfc // selfg * KK)\n",
    "        duf = attk.transpose(-2, -1) @ dx\n",
    "        del attk, uf\n",
    "\n",
    "        dattk = dattk.view(B, H * W, -1)\n",
    "        datt += dattk @ selfw.transpose(-2, -1)\n",
    "        dselfw = att.transpose(-2, -1) @ dattk\n",
    "\n",
    "        duf = duf.permute(0, 2, 3, 4, 1).view(B, -1, H * W)\n",
    "        dx = F.fold(duf, output_size=(H, W), kernel_size=selfk, padding=selfk // 2)\n",
    "\n",
    "        datt = datt.transpose(-1, -2).view(B, nset, H, W)\n",
    "\n",
    "        return dx, datt, None, None, dselfb, dselfw\n",
    "\n",
    "class LayerNormFunction(torch.autograd.Function):\n",
    "\n",
    "    @staticmethod\n",
    "    def forward(ctx, x, weight, bias, eps):\n",
    "        ctx.eps = eps\n",
    "        N, C, H, W = x.size()\n",
    "        mu = x.mean(1, keepdim=True)\n",
    "        var = (x - mu).pow(2).mean(1, keepdim=True)\n",
    "        y = (x - mu) / (var + eps).sqrt()\n",
    "        ctx.save_for_backward(y, var, weight)\n",
    "        y = weight.view(1, C, 1, 1) * y + bias.view(1, C, 1, 1)\n",
    "        return y\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        eps = ctx.eps\n",
    "\n",
    "        N, C, H, W = grad_output.size()\n",
    "        y, var, weight = ctx.saved_tensors\n",
    "        g = grad_output * weight.view(1, C, 1, 1)\n",
    "        mean_g = g.mean(dim=1, keepdim=True)\n",
    "\n",
    "        mean_gy = (g * y).mean(dim=1, keepdim=True)\n",
    "        gx = 1. / torch.sqrt(var + eps) * (g - y * mean_gy - mean_g)\n",
    "        return gx, (grad_output * y).sum(dim=3).sum(dim=2).sum(dim=0), grad_output.sum(dim=3).sum(dim=2).sum(\n",
    "            dim=0), None\n",
    "\n",
    "class LayerNorm2d(nn.Module):\n",
    "\n",
    "    def __init__(self, channels, eps=1e-6):\n",
    "        super(LayerNorm2d, self).__init__()\n",
    "        self.register_parameter('weight', nn.Parameter(torch.ones(channels)))\n",
    "        self.register_parameter('bias', nn.Parameter(torch.zeros(channels)))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        return LayerNormFunction.apply(x, self.weight, self.bias, self.eps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class SimpleGate(nn.Module):\n",
    "    def forward(self, x):\n",
    "        x1, x2 = x.chunk(2, dim=1)\n",
    "        return x1 * x2\n",
    "\n",
    "class KBBlock_s(nn.Module):\n",
    "    def __init__(self, c, DW_Expand=2, FFN_Expand=2, nset=32, k=3, gc=4, lightweight=False):\n",
    "        super(KBBlock_s, self).__init__()\n",
    "        self.k, self.c = k, c\n",
    "        self.nset = nset\n",
    "        dw_ch = int(c * DW_Expand)\n",
    "        ffn_ch = int(FFN_Expand * c)\n",
    "\n",
    "        self.g = c // gc\n",
    "        self.w = nn.Parameter(torch.zeros(1, nset, c * c // self.g * self.k ** 2))\n",
    "        self.b = nn.Parameter(torch.zeros(1, nset, c))\n",
    "        self.init_p(self.w, self.b)\n",
    "\n",
    "        self.norm1 = LayerNorm2d(c)\n",
    "        self.norm2 = LayerNorm2d(c)\n",
    "\n",
    "        self.sca = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(in_channels=c, out_channels=c, kernel_size=1, padding=0, stride=1,\n",
    "                      groups=1, bias=True),\n",
    "        )\n",
    "\n",
    "        if not lightweight:\n",
    "            self.conv11 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c, out_channels=c, kernel_size=1, padding=0, stride=1, groups=1,\n",
    "                          bias=True),\n",
    "                nn.Conv2d(in_channels=c, out_channels=c, kernel_size=5, padding=2, stride=1, groups=c // 4,\n",
    "                          bias=True),\n",
    "            )\n",
    "        else:\n",
    "            self.conv11 = nn.Sequential(\n",
    "                nn.Conv2d(in_channels=c, out_channels=c, kernel_size=1, padding=0, stride=1, groups=1,\n",
    "                          bias=True),\n",
    "                nn.Conv2d(in_channels=c, out_channels=c, kernel_size=3, padding=1, stride=1, groups=c,\n",
    "                          bias=True),\n",
    "            )\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=c, out_channels=c, kernel_size=1, padding=0, stride=1, groups=1,\n",
    "                               bias=True)\n",
    "        self.conv21 = nn.Conv2d(in_channels=c, out_channels=c, kernel_size=3, padding=1, stride=1, groups=c,\n",
    "                                bias=True)\n",
    "\n",
    "        interc = min(c, 32)\n",
    "        self.conv2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=c, out_channels=interc, kernel_size=3, padding=1, stride=1, groups=interc,\n",
    "                      bias=True),\n",
    "            SimpleGate(),\n",
    "            nn.Conv2d(interc // 2, self.nset, 1, padding=0, stride=1),\n",
    "        )\n",
    "\n",
    "        self.conv211 = nn.Conv2d(in_channels=c, out_channels=self.nset, kernel_size=1)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=dw_ch // 2, out_channels=c, kernel_size=1, padding=0, stride=1,\n",
    "                               groups=1, bias=True)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(in_channels=c, out_channels=ffn_ch, kernel_size=1, padding=0, stride=1, groups=1,\n",
    "                               bias=True)\n",
    "        self.conv5 = nn.Conv2d(in_channels=ffn_ch // 2, out_channels=c, kernel_size=1, padding=0, stride=1,\n",
    "                               groups=1, bias=True)\n",
    "\n",
    "        self.dropout1 = nn.Identity()\n",
    "        self.dropout2 = nn.Identity()\n",
    "\n",
    "        self.ga1 = nn.Parameter(torch.zeros((1, c, 1, 1)) + 1e-2, requires_grad=True)\n",
    "        self.attgamma = nn.Parameter(torch.zeros((1, self.nset, 1, 1)) + 1e-2, requires_grad=True)\n",
    "        self.sg = SimpleGate()\n",
    "\n",
    "        self.beta = nn.Parameter(torch.zeros((1, c, 1, 1)) + 1e-2, requires_grad=True)\n",
    "        self.gamma = nn.Parameter(torch.zeros((1, c, 1, 1)) + 1e-2, requires_grad=True)\n",
    "\n",
    "    def init_p(self, weight, bias=None):\n",
    "        init.kaiming_uniform_(weight, a=math.sqrt(5))\n",
    "        if bias is not None:\n",
    "            fan_in, _ = init._calculate_fan_in_and_fan_out(weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            init.uniform_(bias, -bound, bound)\n",
    "\n",
    "    def KBA(self, x, att, selfk, selfg, selfb, selfw):\n",
    "        return KBAFunction.apply(x, att, selfk, selfg, selfb, selfw)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        x = inp\n",
    "\n",
    "        x = self.norm1(x)\n",
    "        sca = self.sca(x)\n",
    "        x1 = self.conv11(x)\n",
    "\n",
    "        # KBA module\n",
    "        att = self.conv2(x) * self.attgamma + self.conv211(x)\n",
    "        uf = self.conv21(self.conv1(x))\n",
    "        x = self.KBA(uf, att, self.k, self.g, self.b, self.w) * self.ga1 + uf\n",
    "        x = x * x1 * sca\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.dropout1(x)\n",
    "        y = inp + x * self.beta\n",
    "\n",
    "        # FFN\n",
    "        x = self.norm2(y)\n",
    "        x = self.conv4(x)\n",
    "        x = self.sg(x)\n",
    "        x = self.conv5(x)\n",
    "\n",
    "        x = self.dropout2(x)        \n",
    "        return y + x * self.gamma\n",
    "\n",
    "\n",
    "class KBNet_s(nn.Module):\n",
    "    def __init__(self, img_channel=3, width=16, middle_blk_num=4, enc_blk_nums=[2,2,2],\n",
    "                 dec_blk_nums=[4,3,2], basicblock='KBBlock_s', lightweight=False, ffn_scale=2):\n",
    "        super().__init__()\n",
    "        basicblock = eval(basicblock)\n",
    "        self.intro = nn.Conv2d(in_channels=img_channel, out_channels=width, kernel_size=3, padding=1, stride=1,\n",
    "                               groups=1, bias=True)\n",
    "\n",
    "        self.encoders = nn.ModuleList()\n",
    "        self.middle_blks = nn.ModuleList()\n",
    "        self.decoders = nn.ModuleList()\n",
    "\n",
    "        self.ending = nn.Conv2d(in_channels=width, out_channels=img_channel, kernel_size=3, padding=1, stride=1,\n",
    "                                groups=1, bias=True)\n",
    "\n",
    "        self.ups = nn.ModuleList()\n",
    "        self.downs = nn.ModuleList()\n",
    "\n",
    "        chan = width\n",
    "        for num in enc_blk_nums:\n",
    "            self.encoders.append(\n",
    "                nn.Sequential(\n",
    "                    *[basicblock(chan, FFN_Expand=ffn_scale, lightweight=lightweight) for _ in range(num)]\n",
    "                )\n",
    "            )\n",
    "            self.downs.append(\n",
    "                nn.Conv2d(chan, 2 * chan, 2, 2)\n",
    "            )\n",
    "            chan = chan * 2\n",
    "\n",
    "        self.middle_blks = \\\n",
    "            nn.Sequential(\n",
    "                *[basicblock(chan, FFN_Expand=ffn_scale, lightweight=lightweight) for _ in range(middle_blk_num)]\n",
    "            )\n",
    "\n",
    "        for num in dec_blk_nums:\n",
    "            self.ups.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(chan, chan * 2, 1, bias=False),\n",
    "                    nn.PixelShuffle(2)\n",
    "                )\n",
    "            )\n",
    "            chan = chan // 2\n",
    "            self.decoders.append(\n",
    "                nn.Sequential(\n",
    "                    *[basicblock(chan, FFN_Expand=ffn_scale, lightweight=lightweight) for _ in range(num)]\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.padder_size = 2 ** len(self.encoders)\n",
    "\n",
    "    def forward(self, inp):\n",
    "        B, C, H, W = inp.shape\n",
    "        inp = self.check_image_size(inp)\n",
    "        x = self.intro(inp)\n",
    "\n",
    "        encs = []\n",
    "\n",
    "        for encoder, down in zip(self.encoders, self.downs):\n",
    "            x = encoder(x)\n",
    "            encs.append(x)\n",
    "            x = down(x)\n",
    "\n",
    "        x = self.middle_blks(x)\n",
    "\n",
    "        for decoder, up, enc_skip in zip(self.decoders, self.ups, encs[::-1]):\n",
    "            x = up(x)\n",
    "            x = x + enc_skip\n",
    "            x = decoder(x)\n",
    "\n",
    "        x = self.ending(x)\n",
    "        x = x + inp\n",
    "\n",
    "        return x[:, :, :H, :W]\n",
    "\n",
    "    def check_image_size(self, x):\n",
    "        _, _, h, w = x.size()\n",
    "        mod_pad_h = (self.padder_size - h % self.padder_size) % self.padder_size\n",
    "        mod_pad_w = (self.padder_size - w % self.padder_size) % self.padder_size\n",
    "        x = F.pad(x, (0, mod_pad_w, 0, mod_pad_h))\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# 커스텀 데이터셋 클래스 정의\n",
    "# class CustomDataset(data.Dataset):\n",
    "#     def __init__(self, noisy_image_paths, clean_image_paths, patch_size = 128, transform=None):\n",
    "#         self.clean_image_paths = [join(clean_image_paths, x) for x in listdir(clean_image_paths)]\n",
    "#         self.noisy_image_paths = [join(noisy_image_paths, x) for x in listdir(noisy_image_paths)]\n",
    "#         self.transform = transform\n",
    "#         self.patch_size = patch_size\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.noisy_image_paths)\n",
    "\n",
    "#     def __getitem__(self, index):\n",
    "#         # 이미지 불러오기\n",
    "#         noisy_image = load_img(self.noisy_image_paths[index])\n",
    "#         clean_image = load_img(self.clean_image_paths[index])\n",
    "\n",
    "#         H, W, _ = clean_image.shape\n",
    "\n",
    "#         # 이미지 랜덤 크롭\n",
    "#         rnd_h = random.randint(0, max(0, H - self.patch_size))\n",
    "#         rnd_w = random.randint(0, max(0, W - self.patch_size))\n",
    "#         noisy_image = noisy_image[rnd_h:rnd_h + self.patch_size, rnd_w:rnd_w + self.patch_size, :]\n",
    "#         clean_image = clean_image[rnd_h:rnd_h + self.patch_size, rnd_w:rnd_w + self.patch_size, :]\n",
    "        \n",
    "#         # transform 적용\n",
    "#         if self.transform:\n",
    "#             noisy_image = self.transform(noisy_image)\n",
    "#             clean_image = self.transform(clean_image)\n",
    "        \n",
    "#         return noisy_image, clean_image\n",
    "\n",
    "\n",
    "class CustomDataset(data.Dataset):\n",
    "    def __init__(self, scan_dir, clean_dir, patch_size = 128, transform=None):\n",
    "        self.scan_dir = scan_dir\n",
    "        self.clean_dir = clean_dir\n",
    "        self.patch_size = patch_size\n",
    "        self.transform = transform\n",
    "\n",
    "        self.scan_paths = sorted(os.listdir(scan_dir))\n",
    "        self.clean_paths = sorted(os.listdir(clean_dir))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.scan_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        scan_path = os.path.join(self.scan_dir, self.scan_paths[index])\n",
    "        clean_path = os.path.join(self.clean_dir, self.clean_paths[index])\n",
    "\n",
    "        # Load the clean and scan images using memory-mapped files\n",
    "        scan_img = self.load_image(scan_path)\n",
    "        clean_img = self.load_image(clean_path)\n",
    "\n",
    "        # Apply data augmentation\n",
    "        scan_img, clean_img = self.augment_image(scan_img, clean_img)\n",
    "\n",
    "        # Convert Y channel images to PIL Images\n",
    "        scan_img = Image.fromarray(scan_img)\n",
    "        clean_img = Image.fromarray(clean_img)\n",
    "\n",
    "        # Apply data transformation if provided\n",
    "        if self.transform is not None:\n",
    "            scan_img = self.transform(scan_img)\n",
    "            clean_img = self.transform(clean_img)\n",
    "\n",
    "        return scan_img, clean_img\n",
    "\n",
    "    def load_image(self, image_path):\n",
    "        # Open the image file using memory-mapped files\n",
    "        with open(image_path, \"rb\") as f:\n",
    "            mmapped_file = mmap.mmap(f.fileno(), length=0, access=mmap.ACCESS_READ)\n",
    "            img_data = mmapped_file.read()\n",
    "\n",
    "        # Read the image data using OpenCV\n",
    "        img_array = np.frombuffer(img_data, dtype=np.uint8)\n",
    "        img = cv2.imdecode(img_array, cv2.IMREAD_COLOR)\n",
    "        \n",
    "        # Convert from BGR to RGB\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        # Y Channel\n",
    "        if channel == 1:\n",
    "            # Convert RGB image to YUV color space\n",
    "            img_yuv = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "\n",
    "            # Extract the Y channel\n",
    "            img_y = img_yuv[:, :, 0]\n",
    "\n",
    "            return img_y\n",
    "        \n",
    "        # RGB\n",
    "        elif channel == 3:\n",
    "            \n",
    "            return img\n",
    "\n",
    "    def augment_image(self, scan_img, clean_img):\n",
    "        # Random crop\n",
    "        # Y Channel\n",
    "        if channel == 1:\n",
    "            rows, cols = clean_img.shape\n",
    "            x = np.random.randint(0, cols - self.patch_size)\n",
    "            y = np.random.randint(0, rows - self.patch_size)\n",
    "            scan_img = scan_img[y:y+self.patch_size, x:x+self.patch_size]\n",
    "            clean_img = clean_img[y:y+self.patch_size, x:x+self.patch_size]\n",
    "            rows, cols = clean_img.shape\n",
    "        # RGB    \n",
    "        elif channel == 3:\n",
    "            rows, cols, _ = clean_img.shape\n",
    "            x = np.random.randint(0, cols - self.patch_size)\n",
    "            y = np.random.randint(0, rows - self.patch_size)\n",
    "            scan_img = scan_img[y:y+self.patch_size, x:x+self.patch_size, :]\n",
    "            clean_img = clean_img[y:y+self.patch_size, x:x+self.patch_size, :]\n",
    "            rows, cols, _ = clean_img.shape\n",
    "    \n",
    "        # Random rotation\n",
    "        angles = [0, 90, 180, 270, 360]\n",
    "        angle = random.choice(angles)\n",
    "        rotation_matrix = cv2.getRotationMatrix2D((cols / 2, rows / 2), angle, 1)\n",
    "        scan_img = cv2.warpAffine(scan_img, rotation_matrix, (cols, rows))\n",
    "        clean_img = cv2.warpAffine(clean_img, rotation_matrix, (cols, rows))\n",
    "\n",
    "        # Random horizontal flip\n",
    "        if np.random.rand() < 0.5:\n",
    "            scan_img = np.fliplr(scan_img)\n",
    "            clean_img = np.fliplr(clean_img)\n",
    "\n",
    "        # Random vertical flip\n",
    "        if np.random.rand() < 0.5:\n",
    "            scan_img = np.flipud(scan_img)\n",
    "            clean_img = np.flipud(clean_img)\n",
    "\n",
    "        return scan_img, clean_img\n",
    "\n",
    "\n",
    "# -----------------------------datasets----------------------------------\n",
    "\n",
    "\n",
    "# 데이터셋 경로\n",
    "noisy_image_paths = 'dataset/train/scan'\n",
    "clean_image_paths = 'dataset/train/clean'\n",
    "\n",
    "# 데이터셋 로드 및 전처리\n",
    "train_transform = Compose([\n",
    "    ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "# 커스텀 데이터셋 인스턴스 생성\n",
    "train_dataset = CustomDataset(noisy_image_paths, clean_image_paths, transform=train_transform)\n",
    "\n",
    "# 데이터 로더 설정\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# valid set 설정\n",
    "split_ratio = 0.8\n",
    "dataset_size = len(train_dataset)\n",
    "train_size = int(dataset_size * split_ratio)\n",
    "validation_size = dataset_size - train_size\n",
    "\n",
    "train_dataset, validation_dataset = torch.utils.data.random_split(train_dataset, [train_size, validation_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "valid_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "# --------------------------------train---------------------------------\n",
    "\n",
    "# GPU 사용 여부 확인\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# DnCNN 모델 인스턴스 생성 및 GPU로 이동\n",
    "model = KBNet_s().to(device)\n",
    "print(summary(model, (3, 128, 128)))\n",
    "\n",
    "# 손실 함수와 최적화 알고리즘 설정\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Set the desired final learning rate\n",
    "final_lr = 0.0001\n",
    "\n",
    "# Calculate the decay factor based on the desired final learning rate\n",
    "gamma = (final_lr / 0.001) ** (1.0 / 50)\n",
    "# Create the ExponentialLR scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=gamma)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 학습\n",
    "best_loss = 9999.0\n",
    "early_stopping_counter = 0 \n",
    "patience = 50\n",
    "valid_losses=[]\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for noisy_images, clean_images in train_loader:\n",
    "        noisy_images = noisy_images.to(device)\n",
    "        clean_images = clean_images.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(noisy_images)\n",
    "        loss = criterion(outputs, noisy_images-clean_images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item() * noisy_images.size(0)\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "    processed = 0.0\n",
    "    for noisy_images, clean_images in valid_loader:\n",
    "        noisy_images, clean_images = noisy_images.to(device), clean_images.to(device)\n",
    "        output=model(noisy_images)\n",
    "        loss = criterion(output, noisy_images-clean_images)\n",
    "        valid_loss += loss.item() * noisy_images.size(0)\n",
    "    valid_loss/=len(validation_dataset)\n",
    "    valid_losses.append(valid_loss)\n",
    "    print('\\nEpoch {}/{}, Valid set : Average loss: {:.4f}\\n'.format(epoch+1, num_epochs, valid_loss))\n",
    "# 현재 val loss가 최소 loss보다 작으면 모델 갱신\n",
    "    scheduler.step()\n",
    "\n",
    "    if valid_loss < best_loss:\n",
    "        best_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'best_dncnn_model.pth')\n",
    "        early_stopping_counter = 0  # 개선이 있으므로 카운터 초기화\n",
    "        print(f\"Saved model checkpoint at epoch {epoch+1}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "    \n",
    "    if early_stopping_counter >= patience:\n",
    "        print(f\"No improvement for {patience} epochs. Early stopping...\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------time-------------------------\n",
    "\n",
    "# 종료 시간 기록\n",
    "end_time = time.time()\n",
    "\n",
    "# 소요 시간 계산\n",
    "training_time = end_time - start_time\n",
    "\n",
    "# 시, 분, 초로 변환\n",
    "minutes = int(training_time // 60)\n",
    "seconds = int(training_time % 60)\n",
    "hours = int(minutes // 60)\n",
    "minutes = int(minutes % 60)\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"훈련 소요 시간: {hours}시간 {minutes}분 {seconds}초\")\n",
    "\n",
    "#---------------------------test-----------------------------\n",
    "\n",
    "\n",
    "\n",
    "model = KBNet_s()\n",
    "model.load_state_dict(torch.load('best_dncnn_model.pth'))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "\n",
    "# 데이터셋 경로\n",
    "noisy_data_path = 'dataset/test/clean'\n",
    "output_path = 'output'\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "class CustomDatasetTest(data.Dataset):\n",
    "    def __init__(self, noisy_image_paths, transform=None):\n",
    "        self.noisy_image_paths = [join(noisy_image_paths, x) for x in listdir(noisy_image_paths)]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.noisy_image_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        noisy_image_path = self.noisy_image_paths[index]\n",
    "        noisy_image = load_img(self.noisy_image_paths[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "\n",
    "        return noisy_image, noisy_image_path\n",
    "\n",
    "test_transform = Compose([\n",
    "    ToTensor(),\n",
    "])\n",
    "\n",
    "# 데이터셋 로드 및 전처리\n",
    "noisy_dataset = CustomDatasetTest(noisy_data_path, transform=test_transform)\n",
    "\n",
    "# 데이터 로더 설정\n",
    "noisy_loader = DataLoader(noisy_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# 이미지 denoising 및 저장\n",
    "for noisy_image, noisy_image_path in noisy_loader:\n",
    "    noisy_image = noisy_image.to(device)\n",
    "    noise = model(noisy_image)\n",
    "\n",
    "    denoised_image = noisy_image - noise\n",
    "    \n",
    "    # denoised_image를 CPU로 이동하여 이미지 저장\n",
    "    denoised_image = denoised_image.cpu().squeeze(0)\n",
    "    denoised_image = torch.clamp(denoised_image, 0, 1)  # 이미지 값을 0과 1 사이로 클램핑\n",
    "    denoised_image = transforms.ToPILImage()(denoised_image)\n",
    "\n",
    "    # Save denoised image\n",
    "    output_filename = noisy_image_path[0]\n",
    "    denoised_filename = output_path + '/' + output_filename.split('/')[-1][:-4] + '.png'\n",
    "    denoised_image.save(denoised_filename) \n",
    "    \n",
    "#    print(f'Saved denoised image: {denoised_filename}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------csv-------------------------------\n",
    "\n",
    "folder_path = 'output'\n",
    "output_file = 'output.csv'\n",
    "\n",
    "# 폴더 내 이미지 파일 이름 목록을 가져오기\n",
    "file_names = os.listdir(folder_path)\n",
    "file_names.sort()\n",
    "\n",
    "# CSV 파일을 작성하기 위해 오픈\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    writer.writerow(['Image File', 'Y Channel Value'])\n",
    "\n",
    "    for file_name in file_names:\n",
    "        # 이미지 로드\n",
    "        image_path = os.path.join(folder_path, file_name)\n",
    "        image = cv2.imread(image_path)\n",
    "\n",
    "        # 이미지를 YUV 색 공간으로 변환\n",
    "        image_yuv = cv2.cvtColor(image, cv2.COLOR_BGR2YUV)\n",
    "\n",
    "        # Y 채널 추출\n",
    "        y_channel = image_yuv[:, :, 0]\n",
    "\n",
    "        # Y 채널을 1차원 배열로 변환\n",
    "        y_values = np.mean(y_channel.flatten())\n",
    "\n",
    "\n",
    "        # 파일 이름과 Y 채널 값을 CSV 파일에 작성\n",
    "        writer.writerow([file_name[:-4], y_values])\n",
    "\n",
    "print('CSV file created successfully.')\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
